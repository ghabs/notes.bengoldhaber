---
tags: decisions tools-for-thought
---
| Categories | #Paper |  
|Source | https://archive.vn/wip/efNwb

An overview of the history, design, and eventual failure of DARPA's futuristic command and control system, Deep Green. [[DeepGreen]] was a [[DARPA]] project attempting to bring simulations into the realm of realtime military operations. It was a "full stack" system for use by in the field commanders to explore potential outcomes of courses of action (COAs). 
It had three separate modules:
- "Blitzkrieg": A simulation tool that models the current battlefield environment and simulates the possible outcomes from a commanders proposed course of action. 
- Crystal Ball: An evaluation tool that assesses the choices generated by Blitzkrieg, ranks and prioritizes in presentation to the user the best plan.
- Commanders Associate: A user interface for the system. The key HCI elements were "sketch to decide" and "sketch to plan", which were drawing interface style tools that would convert the map diagrams into a standardized COA format for the simulator.

As a system the three components would serve as an all purpose decision making aid, helping the commanding officer think through the second and third order effects of a decision. Unlike traditional simulations the real time modeling capability and intuitive interface would make this computer system useful in the field. 

There's a risk with having automated systems develop plans and choose key decision. It might undermine the presence of mind of officers by distracting them or cause them to defer inappropriately to the system and not think through the choices. This is like current concerns around ML interpretability. [[It seems really important that AI systems 'show their work'::rmn]]

The idea of DeepGreen emerged from an Army Modeling and Simulation Office discussion that identified a missing gap in military capabilities. Civilian automated decision systems were outpacing military equivalents. [[Decision Support Systems]] in civilian life include weather prediction, game playing, and securities trading.
    ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fben%2FnCqno3xeEs.png?alt=media&token=91e736e8-8e16-4a48-8f09-fed3eafd6813)

> [[At the heart of the concept of automating staff monitoring functions is concept use of an
operations monitor (OM), which would “monitor the simulation’s progress and compare it with
the real operations".::wrap]]

There were technical challenges. Getting accurate information from the field and integrating it into the simulation was a big one; so was dealing with modeling unanticipated forces arriving on the battlefield ("out of distribution problems"). 

In the end DeepGreen was never fully tried - A new commander at DARPA defunded command and control system research, cutting funding by 75%. This cut the simulation and predictive elements from the program.

DARPA had researched other [[Decision Support Systems]], such as the Real-time Adversarial Intelligence and Decision-making (RAID) and the TIGER system. RAID, which proposed COAs, beat human selected COAs in a competition, but only in lab conditions. The author concludes that military Decision Support Systems still face fundamental challenges of information quality, robustness, and speed of computation.

But... I'm not so sure. Given the success of AlphaZero and similar gameplaying bots it seems to me that a DNN could "solve" existing wargames, and that includes in non-lab conditions (bad information, domain shifts, etc.). Once you have a functioning neural net that could do that, you can optimize it for size and speed (ex. prune it or train a neural net to mimic the larger policy) such that its functional in the field.


